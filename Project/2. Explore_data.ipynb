{"cells":[{"cell_type":"code","source":["# STATISTICAL ANALYSIS 0: Retrieve dataset from HIVE\nfrom os.path import expanduser, join, abspath\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\n\n# Get data warehouse\nspark = SparkSession.builder.appName(\"Milion Songs Dataset\").config(\"spark.sql.warehouse.dir\", abspath('/user/hive/warehouse/songs')).enableHiveSupport().getOrCreate()\ndisplay(spark.sql(\"SELECT count(*) as NUM_SONGS FROM songs\"))"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 1: Missing values\nimport missingno as msno\nfrom pyspark.sql.functions import when, col\nimport numpy as np\nimport pandas as pd\n\nmiss_values = spark.sql(\"SELECT * FROM songs\")\n\n# Turn every 0 values into NaN --> only for visualizing them into this type of graph\nfor feature in miss_values.columns:\n  try:\n    miss_values = miss_values.withColumn(feature, when(col(feature) == 0,np.nan).otherwise(col(feature)))\n  except:\n    pass\n\n# Visualize matrix of missing values (NaN or 0)\ndf = miss_values.toPandas()\nmsno.matrix(df)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 3: Durations across years (filter all valid songs (!=0)) \nbaseQuery = spark.sql(\"select avg(duration) as duration, year from songs group by year\")\ndf_filtered = baseQuery.filter(baseQuery.year !=0)\ndisplay(df_filtered)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 4: Tempo across years\n\nbaseQuery2 = spark.sql(\"select avg(tempo) as tempo, year from songs group by year\")\ndf_filtered = baseQuery2.filter(baseQuery2.year !=0)\ndisplay(df_filtered)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 5: Loudiness across years\n\nbaseQuery3 = spark.sql(\"select avg(loudness) as loudness, year from songs group by year\")\ndf_filtered = baseQuery3.filter(baseQuery3.year !=0)\ndisplay(df_filtered)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 6: Display distribution and correlations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"font.family\"] = \"DejaVu Serif\"\n\nQuery=spark.sql(\"select duration, loudness, tempo, year, density, fadiness, variability, song_hotttnesss, artist_hotttnesss, artist_familiarity from songs\") #EXCLUDE COORDINATES(LAT+LONG) SINCE THE CORRELATION WOLULD MAKE NO SENSE\ndf_filtered = Query.filter(Query.year !=0).filter(Query.song_hotttnesss !=0).filter(Query.tempo !=0).filter(Query.artist_hotttnesss !=0)\n# Trasfrom into pandas for ploting using libraries \ndf = df_filtered.toPandas()\n\n# Pair plot\npp = sns.pairplot(df)\n\nplt.suptitle(\"Distributions and Correlations\", fontsize=50, fontweight=\"regular\", x = 0.5, y = 1.03)\nsns.set_context(\"notebook\", font_scale=1, labelsize=10)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 7: Display correlation through \"Heatmap\"\nimport numpy as np\n\ncorr_matrix = df.corr()\n\nmask = np.zeros_like(corr_matrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr_matrix,mask=mask)\nplt.suptitle(\"Correlation Heatmap\", fontsize=35, fontweight=\"normal\", x = 0.45, y = 1.1)\nsns.set_context(\"notebook\", font_scale=1)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 8: Distrubution of duration \nimport time\nfrom matplotlib import ticker\ndur = spark.sql(\"SELECT duration FROM SONGS WHERE duration != 0\").toPandas()\nminutes=dur[\"duration\"]\n\n# DURATION - Distribution (boxplot)\nfig,ax = plt.subplots(figsize=(30, 3))\nax.boxplot(minutes, vert=False)\nax.text(2.5, 1.2, (\"Median: %s seconds\" % str(datetime.timedelta(seconds=round(minutes.median(),0)))[2:]), fontsize = 20,color = \"black\" ) \n\n# Personalize some parameters #(FOR VISUALIZATION ONLY)\nax.set_title(\"Distribution of song duration\", fontsize=40,fontweight=\"regular\", pad= 20)\nax.set_xlabel(\"Minutes\", fontsize=25, labelpad=10)\nax.axes.yaxis.set_visible(False)\nax.tick_params(labelsize=15)\nax.xaxis.set_major_locator(ticker.MultipleLocator(90))\nlabels = ['','00:00','01:30','03:00','04:30','06:00','07:30','09:00','10:30','12:00','13:30','15:00','16:30','18:00','19:30','21:00','22:30','24:00','25:30','27:00','28:30','30:00','31:30','33:00','34:30','36:00']\nax.set_xticklabels(labels)\nax.set_xlim(0)\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# STATISTICAL ANALYSIS 9: Word cloud for artist genres\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nc=sqlContext.sql('SELECT artist_genre FROM SONGS').toPandas()\nc=Counter(c['artist_genre'].tolist())\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'white',\n    stopwords = STOPWORDS).generate_from_frequencies(c)\n\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'w',\n    edgecolor = 'w')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"2. Explore_data","notebookId":4287416661546827},"nbformat":4,"nbformat_minor":0}
